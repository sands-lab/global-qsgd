Namespace(backend='nccl', batch_size=512, c='DeepFwFM', datadir='./dataset', deep_nodes=400, emb_corr=1.0, emb_r=0.444, embedding_size=10, ensemble=0, gpu=0, h_depth=3, hook='exponential_dithering', init='tcp://127.0.0.1:44444', l2=6e-07, learning_rate=0.001, momentum=0, n_epochs=10, num_deeps=1, numerical=13, prune=1, prune_deep=1, prune_fm=1, prune_r=1, random_seed=666, sparse=0.9, use_cuda=1, use_deep=1, use_ffm=0, use_fm=0, use_fwfm=1, use_fwlw=1, use_logit=0, use_lw=1, use_multi=0, warm=2.0)
Namespace(backend='nccl', batch_size=512, c='DeepFwFM', datadir='./dataset', deep_nodes=400, emb_corr=1.0, emb_r=0.444, embedding_size=10, ensemble=0, gpu=0, h_depth=3, hook='exponential_dithering', init='tcp://127.0.0.1:44444', l2=6e-07, learning_rate=0.001, momentum=0, n_epochs=10, num_deeps=1, numerical=13, prune=1, prune_deep=1, prune_fm=1, prune_r=1, random_seed=666, sparse=0.9, use_cuda=1, use_deep=1, use_ffm=0, use_fm=0, use_fwfm=1, use_fwlw=1, use_logit=0, use_lw=1, use_multi=0, warm=2.0)
Namespace(backend='nccl', batch_size=512, c='DeepFwFM', datadir='./dataset', deep_nodes=400, emb_corr=1.0, emb_r=0.444, embedding_size=10, ensemble=0, gpu=0, h_depth=3, hook='exponential_dithering', init='tcp://127.0.0.1:44444', l2=6e-07, learning_rate=0.001, momentum=0, n_epochs=10, num_deeps=1, numerical=13, prune=1, prune_deep=1, prune_fm=1, prune_r=1, random_seed=666, sparse=0.9, use_cuda=1, use_deep=1, use_ffm=0, use_fm=0, use_fwfm=1, use_fwlw=1, use_logit=0, use_lw=1, use_multi=0, warm=2.0)
Namespace(backend='nccl', batch_size=512, c='DeepFwFM', datadir='./dataset', deep_nodes=400, emb_corr=1.0, emb_r=0.444, embedding_size=10, ensemble=0, gpu=0, h_depth=3, hook='exponential_dithering', init='tcp://127.0.0.1:44444', l2=6e-07, learning_rate=0.001, momentum=0, n_epochs=10, num_deeps=1, numerical=13, prune=1, prune_deep=1, prune_fm=1, prune_r=1, random_seed=666, sparse=0.9, use_cuda=1, use_deep=1, use_ffm=0, use_fm=0, use_fwfm=1, use_fwlw=1, use_logit=0, use_lw=1, use_multi=0, warm=2.0)
Exponential Dithering Hook
Exponential Dithering Hook
Exponential Dithering Hook
Exponential Dithering Hook
Model parameters 607959302, sparse rate 0.00%
Model parameters 607959302, sparse rate 0.00%
Model parameters 607959302, sparse rate 0.00%
Model parameters 607959302, sparse rate 0.00%
Training [1] loss: 0.044956 metric: 0.986722 sparse 0.00% time: 31.091231 s
Training [1] loss: 0.044956 metric: 0.986722 sparse 0.00% time: 31.096304 s
Validation [1] loss: 0.142966 metric: 0.709067 sparse 0.00% time: 31.106394 s
**************************************************
Validation [1] loss: 0.142966 metric: 0.709067 sparse 0.00% time: 31.111736 s
**************************************************
Training [1] loss: 0.044956 metric: 0.986722 sparse 0.00% time: 31.119502 s
Validation [1] loss: 0.142966 metric: 0.709067 sparse 0.00% time: 31.135237 s
**************************************************
Training [1] loss: 0.044956 metric: 0.986722 sparse 0.00% time: 31.143356 s
Validation [1] loss: 0.142966 metric: 0.709067 sparse 0.00% time: 31.159196 s
**************************************************
Model parameters 607959302, sparse rate 0.00%
Model parameters 607959302, sparse rate 0.00%
Model parameters 607959302, sparse rate 0.00%
Model parameters 607959302, sparse rate 0.00%
Training [2] loss: 0.025369 metric: 0.994250 sparse 0.00% time: 29.563990 s
Training [2] loss: 0.025369 metric: 0.994250 sparse 0.00% time: 29.561207 s
Validation [2] loss: 0.174692 metric: 0.697940 sparse 0.00% time: 29.580048 s
**************************************************
Validation [2] loss: 0.174692 metric: 0.697940 sparse 0.00% time: 29.577154 s
**************************************************
Training [2] loss: 0.025369 metric: 0.994250 sparse 0.00% time: 29.567989 s
Training [2] loss: 0.025369 metric: 0.994250 sparse 0.00% time: 29.548677 s
Validation [2] loss: 0.174692 metric: 0.697940 sparse 0.00% time: 29.584203 s
**************************************************
Validation [2] loss: 0.174692 metric: 0.697940 sparse 0.00% time: 29.564947 s
**************************************************
Model parameters 603176411, sparse rate 0.79%
Model parameters 603176411, sparse rate 0.79%
Model parameters 603176411, sparse rate 0.79%
Model parameters 603176411, sparse rate 0.79%
Training [3] loss: 0.018606 metric: 0.996833 sparse 0.79% time: 44.948241 s
Training [3] loss: 0.018606 metric: 0.996833 sparse 0.79% time: 44.951586 s
Validation [3] loss: 0.232836 metric: 0.695432 sparse 0.79% time: 44.963383 s
**************************************************
Validation [3] loss: 0.232836 metric: 0.695432 sparse 0.79% time: 44.966579 s
**************************************************
Training [3] loss: 0.018606 metric: 0.996833 sparse 0.79% time: 44.969562 s
Training [3] loss: 0.018606 metric: 0.996833 sparse 0.79% time: 44.970453 s
Validation [3] loss: 0.232836 metric: 0.695432 sparse 0.79% time: 44.985083 s
**************************************************
Validation [3] loss: 0.232836 metric: 0.695432 sparse 0.79% time: 44.986048 s
**************************************************
Model parameters 598388949, sparse rate 1.57%
Model parameters 598388949, sparse rate 1.57%
Model parameters 598388949, sparse rate 1.57%
Model parameters 598388949, sparse rate 1.57%
Training [4] loss: 0.015532 metric: 0.997921 sparse 1.57% time: 48.561249 s
Training [4] loss: 0.015532 metric: 0.997921 sparse 1.57% time: 48.569101 s
Validation [4] loss: 0.244657 metric: 0.697751 sparse 1.57% time: 48.576405 s
**************************************************
Validation [4] loss: 0.244657 metric: 0.697751 sparse 1.57% time: 48.583990 s
**************************************************
Training [4] loss: 0.015532 metric: 0.997921 sparse 1.57% time: 48.572701 s
Training [4] loss: 0.015532 metric: 0.997921 sparse 1.57% time: 48.573457 s
Validation [4] loss: 0.244657 metric: 0.697751 sparse 1.57% time: 48.588307 s
**************************************************
Validation [4] loss: 0.244657 metric: 0.697751 sparse 1.57% time: 48.589057 s
**************************************************
Model parameters 593674471, sparse rate 2.35%
Model parameters 593674471, sparse rate 2.35%
Model parameters 593674471, sparse rate 2.35%
Model parameters 593674471, sparse rate 2.35%
Training [5] loss: 0.011757 metric: 0.998683 sparse 2.35% time: 51.900314 s
Training [5] loss: 0.011757 metric: 0.998683 sparse 2.35% time: 51.895994 s
Validation [5] loss: 0.338673 metric: 0.681817 sparse 2.35% time: 51.915275 s
**************************************************
Validation [5] loss: 0.338673 metric: 0.681817 sparse 2.35% time: 51.910825 s
**************************************************
Training [5] loss: 0.011757 metric: 0.998683 sparse 2.35% time: 51.905022 s
Training [5] loss: 0.011757 metric: 0.998683 sparse 2.35% time: 51.905254 s
Validation [5] loss: 0.338673 metric: 0.681817 sparse 2.35% time: 51.920954 s
**************************************************
Validation [5] loss: 0.338673 metric: 0.681817 sparse 2.35% time: 51.921432 s
**************************************************
Model parameters 1412161, sparse rate 99.77%
Model parameters 1412161, sparse rate 99.77%
Model parameters 1412161, sparse rate 99.77%
Model parameters 1412161, sparse rate 99.77%
Training [6] loss: 0.008192 metric: 0.999374 sparse 99.77% time: 53.442415 s
Training [6] loss: 0.008192 metric: 0.999374 sparse 99.77% time: 53.439733 s
Validation [6] loss: 0.341514 metric: 0.691803 sparse 99.77% time: 53.457965 s
**************************************************
Validation [6] loss: 0.341514 metric: 0.691803 sparse 99.77% time: 53.455281 s
**************************************************
Training [6] loss: 0.008192 metric: 0.999374 sparse 99.77% time: 53.428608 s
Training [6] loss: 0.008192 metric: 0.999374 sparse 99.77% time: 53.431139 s
Validation [6] loss: 0.341514 metric: 0.691803 sparse 99.77% time: 53.444496 s
**************************************************
Validation [6] loss: 0.341514 metric: 0.691803 sparse 99.77% time: 53.447101 s
**************************************************
Model parameters 1130651, sparse rate 99.81%
Model parameters 1130651, sparse rate 99.81%
Model parameters 1130651, sparse rate 99.81%
Model parameters 1130651, sparse rate 99.81%
Training [7] loss: 0.006522 metric: 0.999601 sparse 99.81% time: 53.429297 s
Training [7] loss: 0.006522 metric: 0.999601 sparse 99.81% time: 53.440933 s
Validation [7] loss: 0.408834 metric: 0.683975 sparse 99.81% time: 53.444371 s
**************************************************
Validation [7] loss: 0.408834 metric: 0.683975 sparse 99.81% time: 53.456012 s
**************************************************
Training [7] loss: 0.006522 metric: 0.999601 sparse 99.81% time: 53.441033 s
Training [7] loss: 0.006522 metric: 0.999601 sparse 99.81% time: 53.435210 s
Validation [7] loss: 0.408834 metric: 0.683975 sparse 99.81% time: 53.456703 s
**************************************************
Validation [7] loss: 0.408834 metric: 0.683975 sparse 99.81% time: 53.450741 s
**************************************************
Model parameters 1122979, sparse rate 99.82%
Model parameters 1122979, sparse rate 99.82%
Model parameters 1122979, sparse rate 99.82%
Model parameters 1122979, sparse rate 99.82%
Training [8] loss: 0.004811 metric: 0.999804 sparse 99.82% time: 53.395656 s
Training [8] loss: 0.004811 metric: 0.999804 sparse 99.82% time: 53.407666 s
Validation [8] loss: 0.372977 metric: 0.697199 sparse 99.82% time: 53.410622 s
**************************************************
Validation [8] loss: 0.372977 metric: 0.697199 sparse 99.82% time: 53.422595 s
**************************************************
Training [8] loss: 0.004811 metric: 0.999804 sparse 99.82% time: 53.391467 s
Training [8] loss: 0.004811 metric: 0.999804 sparse 99.82% time: 53.398421 s
Validation [8] loss: 0.372977 metric: 0.697199 sparse 99.82% time: 53.407061 s
**************************************************
Validation [8] loss: 0.372977 metric: 0.697199 sparse 99.82% time: 53.414197 s
**************************************************
Model parameters 1115364, sparse rate 99.82%
Model parameters 1115364, sparse rate 99.82%
Model parameters 1115364, sparse rate 99.82%
Model parameters 1115364, sparse rate 99.82%
Training [9] loss: 0.002229 metric: 0.999961 sparse 99.82% time: 53.351006 s
Training [9] loss: 0.002229 metric: 0.999961 sparse 99.82% time: 53.352655 s
Validation [9] loss: 0.416146 metric: 0.679665 sparse 99.82% time: 53.366471 s
**************************************************
Validation [9] loss: 0.416146 metric: 0.679665 sparse 99.82% time: 53.368046 s
**************************************************
Training [9] loss: 0.002229 metric: 0.999961 sparse 99.82% time: 53.343240 s
Training [9] loss: 0.002229 metric: 0.999961 sparse 99.82% time: 53.351211 s
Validation [9] loss: 0.416146 metric: 0.679665 sparse 99.82% time: 53.359041 s
**************************************************
Validation [9] loss: 0.416146 metric: 0.679665 sparse 99.82% time: 53.366843 s
**************************************************
Model parameters 1107982, sparse rate 99.82%
Model parameters 1107982, sparse rate 99.82%
Model parameters 1107982, sparse rate 99.82%
Model parameters 1107982, sparse rate 99.82%
Training [10] loss: 0.002268 metric: 0.999911 sparse 99.82% time: 53.304687 s
Training [10] loss: 0.002268 metric: 0.999911 sparse 99.82% time: 53.306000 s
Validation [10] loss: 0.488799 metric: 0.687109 sparse 99.82% time: 53.319610 s
**************************************************
Validation [10] loss: 0.488799 metric: 0.687109 sparse 99.82% time: 53.320884 s
**************************************************
Training [10] loss: 0.002268 metric: 0.999911 sparse 99.82% time: 53.310819 s
Training [10] loss: 0.002268 metric: 0.999911 sparse 99.82% time: 53.312899 s
Validation [10] loss: 0.488799 metric: 0.687109 sparse 99.82% time: 53.326459 s
**************************************************
Validation [10] loss: 0.488799 metric: 0.687109 sparse 99.82% time: 53.328619 s
**************************************************
Number of pruned total parameters: 1107982
Number of pruned total parameters: 1107982
Number of pruned total parameters: 1107982
Number of pruned total parameters: 1107982
